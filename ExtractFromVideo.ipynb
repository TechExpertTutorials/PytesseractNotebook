{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Python Environment (see our video on Python, Conda and VSCode for more details on this topic)  \n",
    "\n",
    "install tesseract from github: https://github.com/UB-Mannheim/tesseract/wiki  \n",
    "add tesseract exe path to environment  \n",
    "\n",
    "conda create pytesseract-env python  \n",
    "conda activate pytesseract-env  \n",
    "conda install pytesseract numpy -c conda-forge  \n",
    "\n",
    "pip install opencv-python  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will detect the frame(s) that credits appear in a video. Our output will be: print the word and the frame number\n",
    "\n",
    "https://www.youtube.com/watch?v=NoMwsPwlV3M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# LIST = ['director', 'directed', 'written', 'writer',\n",
    "#         'producer', 'produced', 'production', 'lead'] \n",
    "\n",
    "LIST = ['template', 'presents', 'production', 'music by', 'casting by']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract first frame from video\n",
    "\n",
    "# path = input('Enter path to file or hls manifest: ')\n",
    "# path = \"https://www.youtube.com/watch?v=NoMwsPwlV3M\"\n",
    "path = \"videoplayback.mp4\"\n",
    "\n",
    "vidcap = cv2.VideoCapture(path)\n",
    "success, frame = vidcap.read()\n",
    "framenbr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_found = []\n",
    "while success:\n",
    "    success,frame = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    # convert to gray scale to get better results from pytesseract\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # extract text, psm is page segment mode\n",
    "    data = pytesseract.image_to_string(gray, lang='eng', config='--psm 6').lower() \n",
    "    if any(word in data for word in LIST):\n",
    "        print(data + '\\nFrame number: ' + str(framenbr))\n",
    "\n",
    "        # save image to file, one image per item in LIST \n",
    "        words = data.split()\n",
    "        for word in words:\n",
    "            # print(word)\n",
    "            if word in LIST:\n",
    "                # print(f\"match: {word}\")\n",
    "                if word not in list_found:\n",
    "                    cv2.imwrite(f\"frame{framenbr}.jpg\", frame)\n",
    "                    list_found.append(word)\n",
    "            # print(f\"list_found={list_found}\")\n",
    "\n",
    "    framenbr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other modes:  \n",
    "0 Orientation and script detection (OSD) only.  \n",
    "1 Automatic page segmentation with OSD.\n",
    "2 Automatic page segmentation, but no OSD, or OCR. (not implemented)  \n",
    "3 Fully automatic page segmentation, but no OSD. (Default)  \n",
    "4 Assume a single column of text of variable sizes.  \n",
    "5 Assume a single uniform block of vertically aligned text.  \n",
    "6 Assume a single uniform block of text.  \n",
    "7 Treat the image as a single text line.  \n",
    "8 Treat the image as a single word.  \n",
    "9 Treat the image as a single word in a circle.  \n",
    "10 Treat the image as a single character.  \n",
    "11 Sparse text. Find as much text as possible in no particular order.  \n",
    "12 Sparse text with OSD.  \n",
    "13 Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dl1.png')\n",
    "data = pytesseract.image_to_string(img, config = r'--psm 6')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dl1.png')\n",
    "data = pytesseract.image_to_string(img, config = r'--psm 11')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dl1.png')\n",
    "data = pytesseract.image_to_string(img, config = r'--psm 3')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "data = pytesseract.image_to_string(gray, config = r'--psm 6')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove noise\n",
    "\n",
    "new_img = cv2.medianBlur(img,3)\n",
    "data = pytesseract.image_to_string(new_img, config = r'--psm 6')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
